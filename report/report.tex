\documentclass[12pt]{report}

\usepackage[letterpaper, hmargin=0.75in, vmargin=0.75in]{geometry}

\usepackage{
    courier,
    algorithm,
    algpseudocode,
    listings,
    underscore,
    authblk,
    hyperref,
    tikz,
    tabularx,
    float,
    graphicx,
	  color
}

\lstset{basicstyle=\footnotesize\ttfamily}

\setlength{\parindent}{0pt}

\begin{document}

\title{RTX Software Design Report}

\author{
    Clement Hoang\\
		20531116\\
    \texttt{c8hoang@uwaterloo.ca}
    \and
    David Su\\
		20516776\\
    \texttt{dysu@uwaterloo.ca}
    \and
    Cole Vander Veen\\
		20503626\\
    \texttt{cgvander@waterloo.ca}
    \and
    Peter Li\\
		20522308\\
    \texttt{y648li@uwaterloo.ca}
}

\date{Winter 2016}

\maketitle


\tableofcontents
\listofalgorithms
\listoffigures

\chapter{Introduction}

The purpose of this report is to outline the design and implementation of the RTX code written by the group members, Clement Hoang, David Su, Peter Li, and Cole Vander Veen, as part of the SE350 course at the University of Waterloo. The OS is designed for a Keil MCB1700 Cortex-M3 board, with a LPC1768 microcontroller.

The report aims to provide documentation for the operating system, in order to facilitate the use and understanding for anyone interested in programming for the OS. As such, this report outlines the global variables used in the OS, then moves on to describing the kernel API in a modular and chronological way. Finally, the report closes with some analysis on the OS, and challenges that the group faced for the duration of the lab.

\chapter{Design Description}

\section{Global Variables and Data Structures}
\begin{itemize}
  \item \texttt{memQueue}: A data structure that models the free physical memory in the OS, by splitting the heap into blocks of equal size. It is represented by a \texttt{memQueue} data structure, which is a linked list of \texttt{MemBlock} nodes of size \texttt{BLOCK_SIZE} (\texttt{BLOCK_SIZE} is a constant defined in the OS). When a process requests memory using the kernel API call \texttt{request\_memory\_block}, a block of memory is dequeued from the \texttt{memQueue} and given to the process.  When a process releases memory, it is enqueued into \texttt{memQueue} again.
    \begin{itemize}
      \item \texttt{MemBlock}: To expand, the \texttt{MemBlock} is a C-struct representing a single block of memory that holds a pointer to the next \texttt{MemBlock} in the queue. There is reserved space at the front of each memory block in case the block needs to hold an \texttt{envelope}. This space is only used if the memory block is being used to send messages.  The \texttt{envelope} contains the following fields:
        \begin{itemize}
          \item \texttt{next}: a pointer to the next envelope in a message queue
          \item \texttt{sender_id}: the process ID of the message sender
          \item \texttt{recv_id}: the process ID of the message receiver
          \item \texttt{send_time}: the time the message was originally sent at
        \end{itemize}
    \end{itemize}
  \item \texttt{gp_pcbs}: A pointer to an array of \texttt{PCB} (Process Control Block) structs. It holds the state of every process control block in the OS, and is interacted with by functions that need to access the \texttt{PCB}s. For example, setting the process priority or getting the process priority uses \texttt{gp_pcbs} to access the priority of a specific \texttt{PCB}.
    \begin{itemize}
      \item \texttt{PCB}: a model of a process and its state. The \texttt{PCB} contains the following fields:
        \begin{itemize}
          \item \texttt{mp_sp}: stack pointer of the process
          \item \texttt{m_pid}: ID of the process
          \item \texttt{m_priority}: priority of the process
          \item \texttt{m_state}: state of the process
          \item \texttt{nextPCB}: pointer to the next \texttt{PCB}, if it is in a queue
          \item \texttt{msgHead}: beginning of the message queue
          \item \texttt{msgTail}: end of the message queue
        \end{itemize}
    \end{itemize}
  \item \texttt{g_proc_table}: an array of \texttt{PROC_INIT} structs that contains process information for initialization. The \texttt{PROC_INIT} contains the following:
    \begin{itemize}
      \item \texttt{m_id}: ID of the process
      \item \texttt{m_priority}: initial priority of the process
      \item \texttt{m_stack_size}: size to allocate for the process in words
    \end{itemize}
  The process table is where the initial \texttt{PCB} data for each user process is defined.  This data is used by the \texttt{process_init} function to create the initialize the \texttt{PCB} for each process.
    \item \texttt{gp_stack}: a pointer to the end of the stack space, which is also the top of the \texttt{memQueue}. When initializing the heap in the function \texttt{heap_init}, no memory past this address may be used as a free memory block.
  \item \texttt{p_end}: a pointer to the beginning of the memory heap, which is also conceptually the first memory block in \texttt{memQueue}. It is calculated by starting at \texttt{\&Image\$\$RW_IRAM1\$\$ZI\$\$Limit}, then incrementing it upon \texttt{PCB} initialization in \texttt{memory_init} to account for the extra space for the \texttt{PCB}s.
  \item \texttt{numOfBlocks}: the number of blocks of \texttt{MemBlock} allocated in the \texttt{heap_init} function call.
  \item \texttt{g_switch_flag}: a boolean flag that indicates whether to continue to run the process before the UART receives an interrupt. If 1, then it will immediately switch, and if it's 0, then it will continue to run the process.
  \item \texttt{gp_current_process}: a pointer to the \texttt{PCB} of the currently running process. It is used in \texttt{process_switch} among other functions that deal with the current process.
  \item \texttt{ReadyPQ}: a linked list of queues (the queues are also implemented as linked lists) of \texttt{PCB} structures. It represents a priority queue of process blocks in the ready queue. This is used for scheduling, for example inside the \texttt{scheduler} function.
  \item \texttt{BlockPQ}: a linked list of queues of \texttt{PCB} structures. It represents a priority queue of process blocks in the blocked queue. This is used when releasing memory to determine which process should be the first to receive memory.  This is used inside the \texttt{k\_release\_memory} function.
  \item \texttt{NUM_OF_PRIORITIES}: a constant that represents the number of priorities in the OS (default = 5). 0-3 represent the normal priorities from highest to lowest, whereas 4 is reserved for the null process.
  \item \texttt{g_buffer}: a circular buffer that keeps track of user input and wraps around at a certain size. It is used in \texttt{kcdProc} and other functions that deal with uart input.
  \item \texttt{gp_buffer}: a pointer to the next location \texttt{g_buffer}. It is used in \texttt{c_UART0_IRQHandler}.
  \item \texttt{g_buffer_end}: a pointer to the last location in \texttt{g_buffer}. It is helpful for calculations in \texttt{kcdProc}.
  \item \texttt{PROC_STATE_E}: An enum which consists of the states:
    \begin{itemize}
      \item \texttt{NEW}: process was just created
      \item \texttt{RDY}: process is on the ready queue
      \item \texttt{RUN}: process is currently running
      \item \texttt{BLK}: process is blocked on memory
      \item \texttt{WAIT}: process is waiting to receive a message
    \end{itemize}
  \item \texttt{MSG_BUF}: This represents the parts of a message that user processes have access to, as opposed to an \texttt{envelope}, which the users do not have access to. A memory block can be treated as a message by casting it to \texttt{MSG_BUF}.  It consists of the following fields:
    \begin{itemize}
      \item \texttt{mtype}: a user defined message type
      \item \texttt{mtext}: a \texttt{char} array which contains the body of the message
    \end{itemize}
\end{itemize}

\section{Memory Management}

\subsection{Memory Overview}

% The ‘heap’ that the processes request memory blocks from is maintained as a linked list. The length of the heap is exactly enough space for thirty memory blocks of size 0x80 (128 bytes). The number of memory blocks can be configured by modifying the NUM_BLOCKS constant.
% Free space nodes keep track of the length of free space following this address and a pointer to the next chunk of unclaimed blocks. These headers are written directly into the blocks as they are returned to the heap. They are free to be overwritten, the only safe header is the starting address of the heap. The heap is shifted by four bytes to protect the last block from ever being overwritten.
% The request and release methods maintain the optimal structure of the list, deleting and overwriting excess or useless nodes.

By keeping track of the \texttt{gp_stack} and \texttt{gp_pcbs} pointers and keeping track of how much memory the \texttt{PCB}s use, then it is possible to do some pointer arithmetic to determine the starting and ending addresses of the heap (the physical memory available to allocate in the RTX).

The implementation of memory management in this RTX involves maintaing a linked list that keeps track of all the available \texttt{MemBlock}s on the heap. Upon process consumption of memory, \texttt{MemBlock}s allocated are removed from the linked list and a reference to the block is kept in the process. Upon release, the \texttt{MemBlock} is appended to the linked list again. This means that the runtime is $O(1)$ for deletion and insertion of blocks.

 The \texttt{MemBlock}s have a user-defined size called \texttt{BLOCK_SIZE}. The system also reserves some space in the beginning of \texttt{MemBlock}s for \texttt{envelope}s. By default, the \texttt{BLOCK_SIZE} is set to 128 bytes.

\begin{figure}[h!]
  \centering
	\includegraphics{memory.png}
\caption{Memory Layout}

\end{figure}

\subsection{Requesting Memory Blocks}

\begin{minipage}{\textwidth}
\begin{lstlisting}[language=C, frame=single]
int k_request_memory_block(void);
\end{lstlisting}
\end{minipage}

This function returns the address of an available \texttt{MemBlock}. The algorithm is analogous to the dequeue function of a queue. It takes the previous head of \texttt{memQueue}, returns it, then updates the linked list accordingly.  It also sets the status of a process to \texttt{BLK} and enqueues the process into the blocked queue if there is no more memory for the process to use.

\begin{algorithm}[H]
  \caption{Requesting memory function}
  \begin{algorithmic}[1]
    \Procedure{request\_memory\_block}{}
      \While{heap is full}
			\State {block the current process}
	  \EndWhile
	  \State {update the free space list}
	  \State {return the address of the top of the block}
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\subsection{Releasing Memory Blocks}

\begin{minipage}{\textwidth}
\begin{lstlisting}[language=C, frame=single]
int k_release_memory_block(void* memory_block);
\end{lstlisting}
\end{minipage}

This function takes a \texttt{MemBlock} parameter. This parameter is a reference to the \texttt{MemBlock} that will be freed. It also returns a flag on whether that operation was a success or not - \texttt{RTX_ERR} or \texttt{RTX_OK}. The algorithm is analogous to the enqueue function of a queue. After some validation logic, it attached the freed memory block to the end of the linked list. It also moves processes into the ready queue if a process is currently blocked.

\begin{algorithm}[H]
  \caption{Releasing memory function}
  \begin{algorithmic}[1]
    \Procedure{release\_memory\_block}{*memory_block}
      \If{this block is the top block of the heap}
			\State {modify heap header node (never gets overwritten)}
	  \EndIf
	  \If{there is free space immediately beneath this block}
			\State {combine them by increasing this block's length}
	  \Else { this block becomes a new block node, is added to the list}
	  \EndIf
	  \If{there is free space immediately beneath this block}
			\State {combine them by increasing this block's length}
	  \EndIf
	  \If{a process is blocked on memory}
			\State {unblock that process, release the processor}
	  \EndIf
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\pagebreak


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Processor Management}

\subsection{Releasing The Processor}
When the processor is released by a process using \texttt{k_release_processor}, the \texttt{scheduler} is called to determine the next process to run. The \texttt{scheduler} will never choose a blocked process to run next.  The \texttt{scheduler} will choose a process at the highest priority level to run at all times.  The processes at the same priority level will be scheduled in a round robin fashion.

After the next process is chosen, a context switch must be performed to safely switch between processes.  The state of the current process must be saved before beginning to execute the following process.

\begin{algorithm}[H]
  \caption{Releasing processor function}
  \begin{algorithmic}[1]
    \Procedure{release\_processor}{}
	  \State {new\_process = scheduler()}
      \State {context switch from the old process to the new process}
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

The algorithm for \texttt{k\_release\_processor} is very simple, as the scheduler and the context switching algorithm implement the heavy functionality.

\subsection{Scheduler}
The scheduler is implemented using the priority queue \texttt{ReadyPQ}.  The process that is dequeued from a priority queue will always be the process with the highest priority.  Blocked \texttt{PCB}s are never added to the \texttt{ReadyPQ}, so the scheduler will never choose a blocked process to run.  Because the most recently enqueued process is always shifted to the back of \texttt{ReadyPQ}, it will run later than the other processes in \texttt{ReadyPQ}, giving us a round robin scheduling system.  This means that the priority queue aligns with the design mentioned above.

\begin{algorithm}[H]
  \caption{Scheduler}
  \begin{algorithmic}[1]
    \Procedure{scheduler}{}
      \If{a process was previously running}
		\If{the previous process is blocked}
			\State {enqueue the previous process into BlockPQ}
		\EndIf
		\If{the previous process is ready}
			\State {enqueue the previous process into ReadyPQ}
		\EndIf
      \EndIf
	  \State{dequeue the next process from ReadyPQ and return it}
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\subsection{Context Switching}
The context switch procedure has three main purposes.  It must set the states of the old process and the new process to appropriate values.  It must also save the stack pointer of the old process, and restore the stack pointer of the new process.  Finally, if the new process is in state \texttt{NEW}, it must pop the exception stack frame from the stack for the new process.

\begin{algorithm}[H]
  \caption{Context Switcher}
  \begin{algorithmic}[1]
    \Procedure{process_switch}{}
      \If{the new process has a state of NEW}
		\If{the new process is different from the old process}
			\If{the old process does not have a state of NEW}
				\If{the old process is not blocked}
					\State{set the old process' state to RDY}
				\EndIf
				\State{save the old process' stack pointer}
			\EndIf
		\EndIf
		\State{set the new process' state to RUN}
		\State{switch to new process' stack}
		\State{pop exception frame from the stack for the new process}
	  \EndIf
	  
	  \If{the new process is different from the old process}
		\If{the old process is not blocked}
			\State{set the old process' state to RDY}
		\EndIf
		\State{save the old process' stack pointer}
	
		\State{set the new process' state to RUN}
		\State{switch to new process' stack}
	  \EndIf
	\EndProcedure
  \end{algorithmic}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Process Priority Management}

\subsection{Get Process Priority}

The get process priority function takes in the process id as a parameter and returns its priority. We denote the priority of -1 if the process is not found. To find the process by its id, we loop through all the pcbs which are stored in gp_pcbs and compare the process_id. If a matching pcb is found, then we retrieve its priority and return. Otherwise, the loop will end without ever finding a process and will return -1.

\begin{algorithm}[H]
  \caption{Get Process Priority}
  \begin{algorithmic}[1]
  \Function {k_get_process_priority}{process_id}
  \State int priority = -1;
  \For {every process in pcb array}
    \If {process found}
      \State priority = process.priority;
      \State return priority;
     \EndIf
  \EndFor
  \State return priority;
  \EndFunction
  \end{algorithmic}
\end{algorithm}

\subsection{Set Process Priority}

The set process priority function takes in the process id and a priority as the parameters and returns if the function has completed successfully. First we loop through all the process ids to see if we can find a process that has matching ids. Then if we have found the process, we check to see if the priority that is being set to is different from the priority it's currently at. Now at this stage we store the old priority and set the new one if its not currently executing, otherwise we would undo the priority change if the priority change would somehow fail. Finally, we release the processor since we need to immediately move the higher priority process because of the change.

\begin{algorithm}[H]
  \caption{Set Process Priority}
  \begin{algorithmic}[1]
  \Function {k_set_process_priority}{int process_id, int priority}
    \If {priority is within valid range}
      \For {every user process}
        \If {process found}
          \If {process.priority is different}
            \State old_priority = process.priority;
            \State process.priority = priority;
            \If {process is not currently executing}
              \State attempt move the process priority, else undo priority
            \EndIf     
            \State release the processor
          \EndIf
        \EndIf
      \EndFor
    \EndIf
  \EndFunction
  \end{algorithmic}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Interprocess Communication}

\subsection{Message Structure}

Every message uses a memory block as its underlying storage component, and has 2 parts: the part visible to the user (the struct \texttt{MSG_BUF}), and the part exclusive to the kernel (the struct \texttt{envelope}). 

Every memory block created in the operating system has the first \texttt{sizeof(envelope)} bytes reserved, in case that memory block is used as a message. The envelope stores metadata about the message, such as the sender, receiver, the send time, etc. 

Every process' \texttt{PCB} has a ``mailbox'', with a linked list of messages sent to that process that have not yet been read. Thus, the envelope also has a pointer pointing to the next envelope in that linked list.

Then, there is the \texttt{MSG_BUF} struct, which is directly accessible by the user processes. The \texttt{MSG_BUF} contains 2 pieces of data: the type of the message (often \texttt{\#defined} as a constant), and the actual body of the message. The body of the message can take up the rest of the memory block (i.e. BLOCK_SIZE - sizeof(envelope) - sizeof(MSG_BUF.mtype)). 


\subsection{Sending Messages}

The send message primitive receives as parameters the intended recipient of the message, and a pointer to the memory block with the actual message. First, a few pieces of metadata is set on the envelope. Then, it merely places that message in the mailbox, located in the \texttt{PCB} of the recipient. Finally, if that message is blocked waiting for a message, it puts that message on the ready queue. Additionally, if that message has higher priority than the current running process, it releases the processor.

\begin{algorithm}[H]
	\caption{Send Message}
	\begin{algorithmic}[1]
		\Function{send_message}{receiver_id, message}
			\State message.sender = current process
			\State message.receiver = receiver_id
			\State enqueue message in the the receiver's mailbox
			\If{receiver was blocked waiting for a message}
				\State put receiver on the ready queue
				\State set receiver's state to Ready
				\If{receiver has higher priority than the current process}
					\State release the processor
				\EndIf
			\EndIf
		\EndFunction
	\end{algorithmic}
\end{algorithm}

In addition to the \texttt{send_message} function specified above, we needed another version of the function that would not preempt under any circumstances. This was necessary for the case when the UART i-process needed to send a message. I-processes must not preempt under any circumstances.

\begin{algorithm}[H]
	\caption{Send Message (Non-preemptive)}
	\begin{algorithmic}[1]
		\Function{send_message_non_preempt}{receiver_id, message}
			\State message.sender = current process
			\State message.receiver = receiver_id
			\State enqueue message in the the receiver's mailbox
			\If{receiver was blocked waiting for a message}
				\State put receiver on the ready queue
				\State set receiver's state to Ready
			\EndIf
		\EndFunction
	\end{algorithmic}
\end{algorithm}


Finally, we created another version of \texttt{send_message} specific to the timer i-process. The timer i-process must send messages to other processes once the timeout expires. However, the sender of that message is not the timer i-process, but rather the original sender. Thus, this necessitated the creation of a new function. Again, this version is non-preemptive for the same reasons as \texttt{send_message_non_preempt}.

\begin{algorithm}[H]
	\caption{Send Message (Timer version)}
	\begin{algorithmic}[1]
		\Function{timer_send_message}{message}
			\State receiver = message.receiver
			\State enqueue message in the the receiver's mailbox
			\If{receiver was blocked waiting for a message}
				\State put receiver on the ready queue
				\State set receiver's state to Ready
			\EndIf
		\EndFunction
	\end{algorithmic}
\end{algorithm}

\subsection{Receiving Messages}

Receive message merely involves checking the current running process' mailbox, and seeing if there is any messages there. If there is, deque that message, and return it immediately. Otherwise, set the current process' state to blocked on receive, and release the processor.

\begin{algorithm}[H]
	\caption{Receive Message}
	\begin{algorithmic}[1]
		\Function{receive_message}{}
			\While{there are no messages in the current process' mailbox}
				\State current_process.state = BLOCKED_ON_RECEIVE
				\State release the processor
			\EndWhile

			\State dequeue the first message in the mailbox
			\State\Return message, sender_id
		\EndFunction
	\end{algorithmic}
\end{algorithm}

Similar to sending messages, receiving messages also needs a non_blocking version, to be used by the i-processes. If there are no messages in an i-process' mailbox, it should never block. Instead, it should return immediately, and indicate that there are no messages. This function is mainly used by the timer i-process.

\begin{algorithm}[H]
	\caption{Receive Message (non-blocking)}
	\begin{algorithmic}[1]
		\Function{receive_message_non_blocking}{process}
			\If{there are no messages in the process' mailbox}
				\State\Return NULL
			\EndIf

			\State dequeue the first message in the mailbox
			\State\Return message, sender_id
		\EndFunction
	\end{algorithmic}
\end{algorithm}


\subsection{Delayed Send}

Delayed send is implemented by sending a message to the timer i-process specifying the time when the message should actually be sent to the intended recipient.

\begin{algorithm}[H]
	\caption{Delayed Send}
	\begin{algorithmic}[1]
		\Function{delayed_send}{receiver, message, delay}
			\State message.sender = current process
			\State message.receiver = receiver
			\State message.send_time = current_time + delay

			\State enqueue the message in the timer i-process's mailbox 
		\EndFunction
	\end{algorithmic}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Interrupts and I-Processes}

\subsection{UART I-Process}

The UART interrupt is enabled to send output to a display, and to receive input from the user. The OS handles those interrupts by registering a \texttt{UART0_IRQHandler} function that will be called whenever a UART interrupt occurs.

The file \texttt{uart_irq.c} is initialized by calling the function \texttt{uart_irq_init}. This function initializes the UART interrupts by setting the appropriate flags and choosing the correct UART port.

Below is the interrupt handling pseudocode, starting with UART0_IRQHandler:
\begin{algorithm}[H]
	\caption{UART Interrupt Handler function (assembly)}
	\begin{algorithmic}[1]
	  \Function{UART0_IRQHandler}{}
	    \State push registers onto stack
	    \State call c_UART0_IRQHandler_wrapper()
	    \State pop registers off stack
	  \EndFunction
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
	\caption{UART Interrupt Handler function wrapper (C)}
	\begin{algorithmic}[1]
	  \Function{c_UART0_IRQHandler_wrapper}{}
	    \State call c_UART0_IRQHandler()
	    \If{there is another ready process with higher priority than the current process}
	      \State call k_release_processor()
	    \EndIf
	  \EndFunction
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
	\caption{Main UART Interrupt Handler function (C)}
	\begin{algorithmic}[1]
	  \Function{c_UART0_IRQHandler}{}
	    \If{receive data available}
	      \State g_char_in = newly received char
	      \If{g_char_in == null character}
	        \State\Return
	      \EndIf

	      \State echoMsg = get memory block (non blocking)
	      \If{echoMsg is not null}
	        \State echoMsg-$>$mtype = ECHO
	        \If{g_char_in == '\textbackslash r'}
	          \State echoMsg-$>$mtext = \verb|"\n\r\0"|
	        \Else
	          \State echoMsg-$>$mtext = g_char_in + \verb|'\0'|
	        \EndIf
	        \State send echoMsg (no preemption) to KCD
	      \EndIf
	      \If{cur_msg is null}
	        \State cur_msg = get memory block (non blocking)
	        \If{cur_msg is null (no more memory)}
	          \State\Return
	        \EndIf

	        \State msg_str_index = 0
	      \EndIf

	      \If{g_char_in == '\textbackslash r' or message about to overflow memory block}
	        \State cur_msg-$>$mtext += '\textbackslash 0'
	        \State cur_msg-$>$mtype = DEFAULT
	        \State send cur_msg (no preemption) to KCD
	        \State reset cur_msg, msg_str_index
	      \Else
	        \State cur_msg-$>$mtext += g_char_in
	      \EndIf
	    \ElsIf{transmit interrupt enabled}
	      \If{*gp_buffer != null character}
	        \State send *gp_buffer
	        \State gp_buffer = next location in circular buffer
	      \Else
	        \State disable transmit interrupt
	        \State send null character
	        \State reset gp_buffer and g_buffer_end
	      \EndIf
	    \EndIf
	  \EndFunction
	\end{algorithmic}
\end{algorithm}

If there is an incoming character, immediately forward it to the KCD (assuming there is free memory) to echo back to the user. Also, add that character to a buffer. Once a newline is encountered, send the entire buffer to the KCD to decode

If there are still messages in the transmit buffer, send the next character. If the character is a null character, disable the transmit interrupt as the transmission is finished.


Also, there is an \texttt{enable_UART_transmit} function that sets the appropriate flags to enable the interrupt for outputting characters. This function is called by the CRT to begin outputting characters.


\subsection{Timer I-Process}

The Timer interrupts are enabled to increment the global timer of the OS and to send messages originally sent by \texttt{delayed_send} at the appropriate times.  The OS handles these interrupts by registering a \texttt{TIMER0_IRQHANDLER} that will be called whenever a timer interrupt occurs.  A timer interrupt will be called every 12500 clock cycles, which takes 1ms to occur.
The timer is initialized by calling the function \texttt{timer\_init}.  This function initializes the timer by setting several flags, including setting the PR field to 12500, which controls how often timer interrupts occur.  This function also initializes other aspects of the timer, including the queue.  Below is the interrupt handling pseudocode.

\begin{algorithm}[H]
	\caption{Timer Interrupt Handler function (assembly)}
	\begin{algorithmic}[1]
	  \Function{TIMER0_IRQHandler}{}
	    \State push registers onto stack
	    \State call c_TIMER0\_IRQHandler
	    \State pop registers off stack
	  \EndFunction
	\end{algorithmic}
\end{algorithm}

The main function of \texttt{TIMER0_IRQHANDLER} is to save the registers of the previously running process and call the \texttt{c_TIMER0_IRQHANDLER}, which does the majority of the computations.  Then it restores the registers to jump back to the process that was running before the interrupt was called.

\begin{algorithm}[H]
	\caption{Timer Interrupt Handler function (C)}
	\begin{algorithmic}[1]
	  \Function{c_TIMER0_IRQHANDLER}{}
	    \State increment global timer count
	    \While{loop forever}
			\State {receive message (non-blocking)}
			\If {there are no more messages}
				\State {break from loop}
			\EndIf
			\State {insert message into Q, sorted by start time}
		\EndWhile
		\While{there are message(s) in Q that have expired}
			\State {dequeue message from Q}
			\State {send the message to its recipient}
		\EndWhile
		\If {there exists a higher priority ready process}
			\State {release the processor}
		\EndIf
	  \EndFunction
	\end{algorithmic}
\end{algorithm}

This C code increments the timer count and processes the messages the timer recevies via \texttt{delayed\_send}.  The messages that need to be sent after a certain time period are stored in the local queue Q, which is sorted by the time that the messages should be sent to their recipients.  This means that the message at the front of the queue is always the message that needs to be sent sooner than the rest.  This algorithm first receives all the messages stored in the timer interrupt's \texttt{PCB} and inserts them into Q.  Then it checks to see which messages need to be sent at the current \texttt{g_timer_count} and sends each of these messages.  This interrupt will only release the processor if there is currently a process in the \texttt{ReadyPQ} with a higher priority than the current running process, allowing the higher priority process to pre-empt the currently running process.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{System Processes}

\subsection{Null Process}

The null process simply releases the processor in an infinite loop.

\begin{algorithm}[H]
	\caption{Null Process}
	\begin{algorithmic}[1]
		\Function{nullProc}{}
			\While{true}
				\State k_release_processor()
			\EndWhile
		\EndFunction		
	\end{algorithmic}
\end{algorithm}

\subsection{CRT Process}

The CRT's sole responsibility is to output the contents of the messages they receive to the UART.

\begin{algorithm}[H]
	\caption{CRT Process}
	\begin{algorithmic}[1]
	  \Function{crtProc}{}
	    \While{true}
	      \State msg = receive\_message()
	      \State copy msg-$>$mtext to output buffer
	      \State enable\_UART\_transmit()
	      \State release\_memory\_block(msg)
	    \EndWhile
	  \EndFunction
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
	\caption{Copy string to circular buffer helper function}
	\begin{algorithmic}[1]
	  \Function{copyToBuffer}{str}
	    \For{each char in str}
	      \State g_buffer[g_buffer_end] = char
	      \State g_buffer_end = (g_buffer_end + 1) mod BUFFER_SIZE
	    \EndFor
	  \EndFunction
	\end{algorithmic}
\end{algorithm}

\subsection{KCD Process}

The KCD's (Keyboard Command Decoder) responsibility is to decode messages that it receives, and forward them to the appropriate process that has registered itself to handle these types of messages.

\begin{algorithm}[H]
	\caption{KCD Process}
	\begin{algorithmic}[1]
	  \Function{kcdProc}{}
	    \State identifiers = empty array
	    \State processes = empty array
	    \State numIdentifiers = 0
	    \While{true}
	      \State msg = receive\_message()
	      \If{msg-$>$mtype == KCD\_REG}
	        \State add msg's identifier to identifiers
	        \State add msg's sender to processes
	        \State numIdentifiers++
	        \State release\_message\_block(msg)
	      \ElsIf{msg-$>$mtype == ECHO}
	        \State send\_message(PID\_CRT, msg)
	      \Else
	        \If{msg-$>$mtext starts with '\%'}
	          \State handler = search for handler in identifiers
	        \EndIf
	        \If{no handler for this type of message}
	          \State release\_memory\_block(msg)
	        \Else
	          \State send\_message(handler, msg)
	        \EndIf

	        \If{msg-$>$mtext begins with '!'}
	          \State search through PCBs for processes in ready state
	          \State debugMsg = create message with those processes
	          \State send\_message(PID\_CRT, debugMsg)
	        \ElsIf{msg-$>$mtext begins with '@'}
	          \State search through PCBs for processes in blocked state
	          \State debugMsg = create message with those processes
	          \State send\_message(PID\_CRT, debugMsg)
	        \ElsIf{msg-$>$mtext begins with '\#'}
	          \State search through PCBs for processes in blocked on message state
	          \State debugMsg = create message with those processes
	          \State send\_message(PID\_CRT, debugMsg)
	        \EndIf
	      \EndIf
	    \EndWhile
	  \EndFunction
	\end{algorithmic}
\end{algorithm}

This processes repeatedly receives messages. If it is a keyboard command registration, the process saves the identifier along with the process that is registered to handle those commands. If it is an echo command, the message is merely forwarded to the CRT. Otherwise, if the message is an actual command (i.e. it starts with a '\%'), the message is forwarded to the process that is registered to handle it, if it exists. Finally, if the message begins with any debug hotkey, the corresponding debug output is sent to the CRT.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{User Processes}

\subsection{Wall Clock Process}

This process receives messages to reset, start at a specified time, and stop the wall clock. Once started, the clock will print the elapsed time every second.

\begin{algorithm}[H]
	\caption{Wall Clock Process}
	\begin{algorithmic}[1]
	  \Function{wallClockProc}{}
	    \State register itself with KCD to handle '\%W' commands
	    \State id = 0
	    \While{true}\texttt{}
	      \State msg = receive\_message()
	      \If{msg contains reset command}
	        \State id++
	        \State time = 0
	        \State send increment time command to itself, delayed 1 second
	        \State construct time string, send to CRT to print
	      \ElsIf{msg contains increment command}
	        \If{msg's id == id}
	          \State time++
	          \State send increment time command to itself, delayed 1 second
	          \State construct time string, send to CRT to print
	        \Else
	          \State release\_memory\_block(msg)
	        \EndIf
	      \ElsIf{msg contains a start at specified time command}
	        \State id++
	        \State time = parseTime(msg)
	        \State send increment time command to itself, delayed 1 second
	        \State construct time string, send to CRT to print
	      \ElsIf{msg contains stop command}
	        \State id++
	        \State release\_memory\_block(msg)
	      \Else
	        \State release\_memory\_block(msg)
	      \EndIf
	    \EndWhile
	  \EndFunction
	\end{algorithmic}
\end{algorithm}

\subsection{Set Priority Process}

This process registers itself with the KCD to handle ``\%C'' commands. It accepts as parameters a process id, and the new priority for that process.

\begin{algorithm}[H]
	\caption{Set Priority Process}
	\begin{algorithmic}[1]
	  \Function{setPriorityProc}{}
	  	\State send message to KCD to register itself to handle ``\%C'' commands

	  	\While{true}
	  		\State msg = receive new message
	  		\State parse msg's string to get the process_id and new priority to change to
	  		\If{error parsing string}
	  			\State print error message
	  			\State \textbf{continue}
	  		\EndIf

	  		\State set_process_priority(process_id, new_priority)
	  		\If{set_process_priority returned error code}
	  			\State print error message
	  		\EndIf
	  	\EndWhile
	  \EndFunction
	\end{algorithmic}
\end{algorithm}


% David - I don't think it's necessary to talk about stress tests
% \subsection{Stress Test Processes}
% dfdasfasdfads

\section{Initialization}

We initialize the kernel in \texttt{k\_rtx\_init.c}. In the initialization function, we initialize each of:
\begin{enumerate}
	\item timer 0
	\item timer 1
	\item UART0 interrupt driven
	\item UART1 polling
	\item memory
	\item PCBs
	\item heap 
\end{enumerate}

The timers are initialized by setting appropriate configuration parameters such as the freqency. The UART is initialized by enabling UART interrupts and setting configuration parameters. The memory is initialized by allocating space for the each of the \texttt{PCB}s. Then, the fields in \texttt{PCB}s are populated from data in the process table, such as each process's priority, stack size, etc. Then, stack space is allocated in memory based on how much each process requested. Then, all \texttt{PCB}s that require scheduling are placed on the ready queue. Finally, after the \texttt{PCB}s are allocated in the lower memory addresses, and the stacks are allocated in the higher memory addresses, all remaining memory in between is split up into equally sized blocks, to be used as the heap. 

One possible configuration parameter is the \texttt{BLOCK_SIZE} of the heap memory blocks. By default, it is 128 bytes. However, it can be tuned to smaller and larger values to fit the specific use case of the operating system, in order to reduce internal fragmentation.

In addition, user processes can tune their relative priorities to each other, to affect how they are scheduled, and they can request whatever stack size they require to properly function.

\section{Testing}

For P1 and P2, there were two phases to our testing procedure.  At first, the group wrote many lightweight processes to test a large variety of boundary cases.  Often one test was run at a time to minimize conflicts between tests and make debugging easier.  By doing this we could catch the vast majority of bugs quickly and evaluate our OS in a controlled environment.

After the first phase of testing, we wrote more formal test cases to display the functionality of our OS for the demo.  During our formal testing we dedicated \texttt{proc1} to displaying the output before our tests and the final results. Each individual test had one or more processes dedicated to running and verifying the results of the test.  While an individual test is being run, every process that isn't dedicated to running the test simply releases the processor.  Again, this minimizes the possibility that our tests will conflict and cause unexpected results.

\subsection{P1}

While testing P1, our informal tests were devoted to testing the memory management, the functions to set/get the priority of processes, and the scheduler.  When testing boundary cases, we attempted to achieve node coverage of our code by testing every every permutation of removing/adding items to our queues.  For example, we tried tests where every process became blocked to ensure that the \texttt{ReadyPQ} would function correctly when removing all \texttt{PCB}s (except the null \texttt{PCB}) from it.

Here are our formal test cases:

\begin{itemize}
	\item \texttt{1}: A test to check if \texttt{get_process_priority} and \texttt{set_process_priority} function correctly.  The process dedicated to this test:
    	\begin{itemize}
			\item Runs \texttt{get_process_priority} on itself
            \item Sets its own priority to a different value using \texttt{set_process_priority}, then runs \texttt{get_process_priority} on itself again
            \item Runs \texttt{get_process_priority} on a different process
            \item Sets the priority of another process to a different value using \texttt{set_process_priority}, then runs \texttt{get_process_priority} on that process.
		\end{itemize}
    	If \texttt{get_process_priority} returns the correct priority level all four times, the test passes.  Otherwise it fails.
	\item \texttt{2}: A test to check if the scheduler functions correctly with regard to differing priority levels (ie. it will not run a process if another process has a higher priority level).  The process dedicated to this test first sets its own priority higher than the priority of every other process.  Then it releases the processor.  Since it is the highest priority process, the process should be scheduled to run again, and no other processes should run.  If any other processes run during this time, the test fails.  Otherwise the test passes.
	\item \texttt{3}: A test to determine whether memory allocation functions correctly.  The process dedicated to this test first requests several memory blocks.  It then writes data to these memory blocks.  Finally, the process reads the data back from the memory blocks.  If the data is correct, the test passes.  Otherwise the test fails.
	\item \texttt{4}: A test to determine if the OS behaves correctly when all memory is used up.  The first process dedicated to this test requests one block of memory.  Then the second process runs, requesting memory blocks until the system runs out of memory and the process becomes blocked on memory.  After that, the first process runs again and releases its block of memory.  If everything functions correctly, the test passes.
\end{itemize}

\subsection{P2}

For P2, our informal testing mainly focused on the message passing algorithms, the wall clock, and command registration.  The majority of our informal tests were centered around how the wall clock and command registration would interact with the rest of our OS design.  Normally we would run the wall clock while running our tests to ensure that they did not interfere with the wall clock's operation.  We also tested our functions from P1 to ensure that they still functioned correctly in an environment with interrupts enabled.

Here are our formal test cases:

\begin{itemize}
	\item \texttt{1}: A test to evaluate \texttt{send_message} and \texttt{receive_message}.  The first process dedicated to this test sends the message \texttt{"hi"} using \texttt{send_message} to the second process.  The second process receives the message using \texttt{receive_message}, and verifies that the sender is the first process.  It also verifies that the message is correct.  Afterwards, the second process sends the message \texttt{"bye"} back to the first process, which verifies the message in the same way.  If both messages are correct, the test passes.  Otherwise the test fails.
    \item \texttt{2}: A test to verify that \texttt{delayed_send} is functioning correctly.  The process dedicated to this test sends four messages to itself with varying delays, in the following order:
    \begin{itemize}
		\item The message \texttt{"200"} with a delay of 200ms
        \item The message \texttt{"100"} with a delay of 100ms
        \item The message \texttt{"50"} with a delay of 50ms
        \item The message \texttt{"201"} with a delay of 201ms
	\end{itemize}
    The process then receives all four messages.  It confirms that each message was received in the proper order.  If the messages are correct, the test passes, otherwise it fails.
    \item \texttt{3}: A test of the command registration.  The process dedicated to this test first registers itself by sending the command \texttt{"\%A"} to the KCD.  Then it sends the message \texttt{"\%A ABCD"} to the KCD, which should eventually be sent back to the process itself by the KCD.  Finally, it receives the message and checks its validity.  If the correct message is received, the test passes, otherwise it fails.
\end{itemize}

\subsection{P3}

The formal test cases for P3 were processes A, B and C as outlined in the lab manual.  We tested many different combinations of priority levels for these three processes.  On some priority levels (such as HIGH, MEDIUM, LOW for A, B and C respectively), there was a deadlock during the OS' operation, due to process C being unable to request a memory block to allow itself to hibernate.  We concluded that while our OS' design is not capable of preventing this type of deadlock, this is not outside the standard operation for our OS.

\section{Major Design Changes}

One major change that occurred between P1 and P2 was how the memory blocks were structured. In P1, we returned a pointer to the very first byte in the memory block whenever memory was requested, giving user processes complete access to every byte in the memory block. However, in P2, we discovered that this implementation was no longer feasible. When messages get sent using a memory block, there needs to be space in the block for the OS to store metadata about that message, such as the sender, receiver, etc. Therefore, the major design change was to always leave $x$ bytes at the beginning of each memory block for the kernel to store the metadata, and return a pointer to the beginning of the block + $x$ bytes. This required changing code that assumed it had the entire memory block available to use.

A major stumbling block was a hardfault we were getting in P1. At that time, we did not understand the difference between the difference between \texttt{k_} prefixed functions and non-\texttt{k_} prefixed functions. It took many hours of debugging to realize that the non-\texttt{k_} prefixed functions invoke the SVC Handler, which changed the processor into kernel mode, allowing us to execute priviledged instructions. When calling the \texttt{k_} prefixed functions from a user process, it immediately hardfaulted since it was trying to execute priviledged instructions.

Another issue we ran into in P2 was a interrupt issue where our kernel primitives were being interrupted by the timer and UART i-processes, causing undefined behaviour. This problem was fixed by calling \texttt{__disable_irq} and \texttt{__enable_irq} to disable and re-enable interrupts at the beginning and end of kernel primitives.


If we were to start this project again, we would like to further improve the modularity of the code by furthering breaking it up into different files. Additionally, our naming conventions are quite inconsistent, and we would like to improve that as well. This would make our code much cleaner and more elegant. 

\chapter{Lessons Learned}

Upon the completion of this project, the group has gained many valuable insights. This includes things like code quality, source control, and team dynamics.

\section{Version Control}
For our codebase, we used Git as version control. At first, it was a bit painful because we were mostly committing to the master branch and we haven't found out which files to add to the .gitignore yet. This led to a lot of merge conflicts from differing binary files.
However, when the project was in a more stable state, we later progressed to branching out for different tasks and modules. This proved to be quite helpful because it allowed us to separate concerns and work on tasks indepdently.
One way we could have improved this is by having a systematic review process. Because of the team's lack of periodic code reviews and the fact that we divided the work up, the team did not have the opportunity to learn about work that other team members worked on, resulting in a team whose knowledge was extremely speciaized and exclusive for each individual member. This meant that bugs relating to a certain module can only be understood by some members of the team, which sometimes slowed progress down. To improve on this, the team could have periodic code reviews to keep everyone up to date and knowledgable in all parts of the codebase.

\section{Code Management}
When the group first started off coding, the code was extremely unmodular, files were monolithic, comments were lacking, and globals were overly used. This made the code quite messy to look at, and as we progressed through the different parts of the lab, we found it increasingly difficult to debug and navigate through our codebase. Somewhere between P2 and P3, we hit a wall where our RTX had some fundamental bugs with regard to scheduling. However, it was very hard to trace this bug down with our style of code. We dedicated a few days to refactoring the code base; we added comments on hard to understand expressions, we tried to reduce the use of global variables if they were not needed, and we separated long functions into smaller re-usable components. The end result was that unit testing was a lot easier.

\section{Logging and Output}
For some memory issues, it was extremely hard to debug. Even when tracing through the debugger, looking at pointer values is not always the most intuitive. In order to make development easier, we decided to add scoped debug flags in our RTX in order to trace bugs without convoluting the output. For example, we had a \texttt{MEM_DEBUG} flag which could be enabled to output the available amount of memory blocks after each transaction in order to debug a memory leak, and have the default \texttt{DEBUG} flag enabled for less specialized debugging. This allowed us to more intuitively track errors down.

\chapter{Team Dynamics and Individual Responsibilities}
The team members did not enforce a strict task allocation process for deciding each members' responsibilities. Generally however, the scheduling process is similar to the following scenario:
Upon the initial lab introduction, all four of the members would be present, in order to discuss the material and areas of interest. Then, the members would split into two pairs to work on the parts they chose respectively, using pair programming concepts, and communication both online and offline. If one pair is finished earlier than the other, then they would usually group up with the remaining pair to work through the problem. Otherwise, they would colloratively merge the parts they've worked on into a final workiing product before the deadline.

\chapter{Timing Analysis}

In order to time various functions of our OS, we implemented a second timer.  The original timer for our OS, used to implement the \texttt{delayed_send} function, triggers an interrupt every 12500 clock cycles, which is equivalent to 1ms.  However, the functions \texttt{request_memory_block}, \texttt{send_message} and \texttt{receive_message} all perform their function in far less than 1ms, so this timer is useless for timing them.

In response to this, we implemented a timer that interrupts once every 13 clock cycles.  The formula for calculating the period of time between interrupts was found in the timer.c file.  It is $2*(\textnormal{\# clock cycles per interrupt})*(\frac{1}{25}) * 10^{-6} s = \textnormal{period between interrupts}$.  Using this formula, we calculated the period between interrupts for our new timer to be 1.04 microseconds.

With this timer we could time our functions meaningfully.  For each kernel function that we wanted to test, we wrote a process that checks the time on this timer and runs the kernel function we wanted to test 70 times consecutively.  After the test has been run, we record the new time on the timer and compare to the previous value to determine how long the operation of the kernel functions took.  The differences in timing due to the incrementing of our timers and from the processing of the while loop surrounding our functions calls was deemed to be negligible and thus they are not analyzed.

In the time it took for \texttt{request_memory_block} to be called 70 times, there were 136 interrupts from our timer.  At 1.04 microseconds per interrupt, this takes 141.44 microseconds total for all 70 function calls.  This means that a single functions call required approximately 2.02 microseconds.

Similarly, in the time it took for \texttt{send_message} to be called 70 times, there were 82 interrupts from our timer.  This translates to 1.22 microseconds per function call.

Finally, we determined that 116 interrupts occurred while \texttt{receive_message} was called 70 times.  This means that each function call required 1.72 microseconds.  Note that 70 messages were sent to our process before we began testing, so no time was spent in a WAIT state.

\end{document}
